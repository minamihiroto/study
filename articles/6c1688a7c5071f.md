---
title: "Webã‚«ãƒ¡ãƒ©ã§æ„Ÿæƒ…ã‚’å–å¾—ã™ã‚‹è‡ªä½œAPIã‚’ä½œã£ã¦ã¿ãŸ"
emoji: "ğŸ‘¶"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: ["Azure", "FaceAPI", "FastAPI"]
published: true
---

ãƒ¢ãƒ–ãƒ—ãƒ­ã§ä½œæˆã—ãŸã‚ˆ

- sacoã•ã‚“(https://twitter.com/minato0os)
- ã‚ã‚ã ã‚„ã™ãªã‚Šã•ã‚“(https://twitter.com/yasunari_output)

### ä½œã£ã¦ãã‚‚ã®ã‰

FastAPIã§FaceAPIã‚’å©ã„ã¦ã€æ„Ÿæƒ…å€¤ã‚’è¿”ã™ã¨ã„ã†ã‚‚ã®
ä»Šå›ä½œã£ãŸã‚‚ã®ã¯æ³£ãé¡”ã‚’æ¤œå‡ºã™ã‚‹ã¨éŸ³æ¥½ãŒæµã‚Œå‡ºã—ã€èµ¤ã¡ã‚ƒã‚“ã‚’è‡ªå‹•ã§ã‚ã‚„ã™ã¨ã„ã†ã‚³ãƒ³ã‚»ãƒ—ãƒˆã®ã‚‚ã¨ä½œã‚‰ã‚ŒãŸ
ngrokãªã©ã‚’ä½¿ã„ã€ã„ã‚ã‚“ãªäººã«ä½¿ã£ã¦ã¿ã¦æ¬²ã—ã‹ã£ãŸã®ã§ã€OpenCVãªã©ã¯ä½¿ã‚ãšã€webä¸Šã§ä½¿ãˆã‚‹ã‚ˆã†ã«ã—ãŸ

ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹æˆã¯ä¸‹è¨˜ã®é€šã‚Š

project/
  â”œ face.py
  â”œ main.py
  â”‚
  â”œ static/
  â”‚  â”” img/ ã“ã“ã«ä¸€åº¦ç”»åƒã‚’ä¿å­˜ã™ã‚‹
  â”‚  â”” sound/
  â”‚     â”” music.mp3
  â”‚
  â”” templates/
     â”” index.html

### æ›¸ã„ã¦ã„ãã…
Azureã§FaceAPIã®ãƒªã‚½ãƒ¼ã‚¹ã‚’ä½œæˆã—ã¦ãŠã‚Šã€ã‚­ãƒ¼ã¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’å–å¾—ã—ã¦ã„ã‚‹å‰æã§æ›¸ã„ã¦ã„ã

ã¾ãšFaceAPIã‚’å©ããŸã‚ã®ã‚³ãƒ¼ãƒ‰ã‚’face.pyã«æ›¸ã„ã¦ã„ã
æ„Ÿæƒ…ã®jsonã•ãˆå–ã£ã¦ãã‚Œã‚Œã°ã„ã„ã®ã§ã€ä¸‹è¨˜ã®ã‚ˆã†ã«è¨˜è¿°
```python face.py
import cognitive_face as CF

KEY = '{Faceã‚­ãƒ¼1orã‚­ãƒ¼2}'
BASE_URL = '{ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ}/face/v1.0'

CF.Key.set(KEY)
CF.BaseUrl.set(BASE_URL)

def face_api(image_url):
    result = CF.face.detect(image_url, attributes="emotion") # æ„Ÿæƒ…ã‚’å–å¾—
    return result
```
æ¬¡ã«APIã‚’FastAPIã§ä½œæˆã—ã¦ã„ã
ãªã‚“ã‹ã‚ã£ã¡ã‚ƒimportã—ã¦ã‚‹ã‘ã©ã“ã‚“ãªã‚‚ã‚“ï¼Ÿæ•™ãˆã¦å‰ã„äºº

ç”»åƒã‚’ä¿å­˜ã—ãªã„ã¨ãƒ‡ãƒ¼ã‚¿ã‚’FaceAPIã«æŠ•ã’ã‚‹ã“ã¨ãŒã§ããªã‹ã£ãŸã®ã§ã€ä¿å­˜ã™ã‚‹ã“ã¨ã«
ãŸã ä¸Šæ›¸ãã‚’ã™ã‚‹ã®ã§ã€å¸¸ã«ï¼‘ãƒ•ã‚¡ã‚¤ãƒ«ãŒä¿å­˜ã•ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹ï¼ˆã“ã‚Œã ã¨ã„ã‚ã‚“ãªäººãŒåŒæ™‚ã«è§¦ã£ã¦ã‚‹ã¨ãŠã‹ã—ãªã“ã¨ã«ãªã‚‹ã®ã¯è¨€ã‚ãšã‚‚ãŒãªã ã‘ã©æœªå®Ÿè£…ï¼‰

ä¸€å®šä»¥ä¸Šã®æ‚²ã—ã„æ„Ÿæƒ…ã‚’å–å¾—ã™ã‚‹ã¨JSONå½¢å¼ã§è¿”ã™ã‚ˆã†ã«ä½œæˆ
```python main.py
from fastapi import FastAPI, Request # FastAPIã®ä»•æ§˜ã§requestãŒãªã„ã¨ã€ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãŒè¡¨ç¤ºã•ã‚Œãªã„
from fastapi.templating import Jinja2Templates # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ(html)ä½¿ç”¨æ™‚ã«åˆ©ç”¨
from fastapi.staticfiles import StaticFiles # é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•çš„ã«æä¾›
from pydantic import BaseModel # å‹æƒ…å ±ã‚’æä¾›ã—ã¦ãã‚Œã‚‹
import base64
from face import face_api
from io import BytesIO # ãƒ¡ãƒ¢ãƒªä¸Šã§ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã‚’æ‰±ã†ãŸã‚ã®æ©Ÿèƒ½
from PIL import Image # ç”»åƒã®å–ã‚Šè¾¼ã¿ã€ä¿å­˜ã€è¡¨ç¤ºå‡¦ç†

app = FastAPI()
templates = Jinja2Templates(directory = 'templates')
app.mount("/static", StaticFiles(directory="static"), name="static")

@app.get('/')
def root(request: Request):
  return templates.TemplateResponse('index.html',dict(request = request))

class ImageData(BaseModel):
  data: str

@app.post('/')
def root_post(image_data: ImageData):

  s = image_data.data
  target = 'data:image/jpeg;base64,' # ã„ã‚‰ãªã„æ–‡å­—åˆ—
  idx = s.find(target) # ã„ã‚‰ãªã„æ–‡å­—åˆ—ã‚’ã‚‚ã¨ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ¢ã™
  r = s[idx+len(target):] # ã„ã‚‰ãªã„æ–‡å­—åˆ—ä»¥é™ã‚’æŠ½å‡º

  img_raw = base64.b64decode(r) # ãƒ‡ã‚³ãƒ¼ãƒ‰
  img = Image.open(BytesIO(img_raw)) # ç”»åƒã®èª­ã¿è¾¼ã¿

  img.save("static/img/image.jpeg") # å¸¸ã«ä¸Šæ›¸ãä¿å­˜
  image_url = 'static/img/image.jpeg'

  result = face_api(str(image_url)) # FaceAPIã‚’å©ã

  emotion = (result[0]['faceAttributes']['emotion']['sadness']) # JSONã‹ã‚‰ç‰¹å®šã®æ•°å€¤ã‚’æŠ½å‡º

  if emotion >= 0.7 :
    return {"result":"æ³£ã„ã¦ã‚‹ã‚ˆï¼"} # ã‚³ã‚³è‹¦æˆ¦ãƒã‚¤ãƒ³ãƒˆ
  else:
    return {"result":"æ³£ã„ã¦ãªã„ã‚ˆï¼"}
```
jsã¯åˆ‡ã‚Šå‡ºã—ã¦ãŠãã¹ãæ´¾ã ã‘ã©ã€ã¡ã‚‡ã£ã¨æ™‚é–“ãŒãªã‹ã£ãŸã®ã§ã€ã¨ã‚Šã‚ãˆãšindex.html

ç„¡æ–™æ ã‚’è¶…ãˆãªã„ç¨‹åº¦ï¼ˆ5ç§’ã«ä¸€å›ï¼‰ã«é¡”èªè¨¼ã‚’å®Ÿè¡Œã™ã‚‹ã‚ˆã†ã«è¨­å®š
```html index.html
<!DOCTYPE html>
<html lang="ja">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <script src="https://cdn.jsdelivr.net/npm/axios/dist/axios.min.js"></script>
    <title>Document</title>
  </head>

  <body>
    <div>
      <h1>WEBã‚«ãƒ¡ãƒ©ã®æ˜ åƒã‚’è¡¨ç¤º</h1>
      <div>
        <video id="video" width="320" height="240"></video>
        <canvas id="canvas" width="320" height="240" style="opacity: 0;"></canvas>
      </div>
    </div>
    <script>
      const video = document.getElementById("video");
      navigator.mediaDevices // webã‚«ãƒ¡ãƒ©ã‚’èµ·å‹•
        .getUserMedia({
          video: true,
          audio: false,
        })
        .then((stream) => {
          video.srcObject = stream;
          video.play();
        })
        .catch((e) => {
          console.log(e);
        });

      const makePicture = () => { // webã‚«ãƒ¡ãƒ©ã®æƒ…å ±ã‹ã‚‰ç”»åƒã‚’ä½œæˆ
        const ctx = canvas.getContext("2d");
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
        const dataURL = canvas.toDataURL("image/jpeg");
        return postImg(dataURL);
      };
      setInterval(makePicture, 5000);

      const music = new Audio('static/sound/music.mp3');

      async function postImg(dataURL) { // ç”»åƒæƒ…å ±ã‚’è‡ªä½œAPIã«é€ä¿¡ã€å¸°ã£ã¦ããŸå€¤ã«ã‚ˆã£ã¦ã¯éŸ³æ¥½ãŒæµã‚Œã‚‹ã‚ˆã†ã«è¨­å®š
        const HEADER = { headers: { "Content-Type": "application/json" } };
        const params = {
          data: dataURL,
        };
        const response = await axios.post("/", params, HEADER); // ã‚³ã‚³è‹¦æˆ¦ãƒã‚¤ãƒ³ãƒˆ2

        if (response.data.result == "æ³£ã„ã¦ã‚‹ã‚ˆï¼"){
          music.play();
        } else {
          music.pause();
        }
      };
    </script>
  </body>
</html>
```
ä»¥ä¸Š

- jsã‹ã‚‰FastAPIã«ã†ã¾ãç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’é€ä¿¡ã™ã‚‹æ–¹æ³•
- FastAPIã‹ã‚‰jsã«å€¤ã‚’æ¸¡ã™æ–¹æ³•

ä¸Šè¨˜äºŒç‚¹ã§è‹¦æˆ¦ã—ãŸ
