---
title: "自分専用のAIレコーダーを自作したい①"
emoji: "🎙️"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["Python","Whisper","pyannote", "huggingface"]
published: true
---

最近youtubeでいろんなガジェット系の方が紹介されている「Plaud Note」
これがあれば自分の忘れっぽい記憶を外部化できるし、第二の私を作れるのでは!?そう思って購入を検討しました。

いざ調べてみると少し気になる点があったので、**「Plaud Note Pro のようなAIレコーダーを自分で作れないか？(どうせならお金かけずに)」** というテーマで、  
WhisperX × Pyannote.audio を使ったローカル自作環境を構築した備忘録です。

前提、私はこの手の技術に殆ど触れてこなかったので、自作するとどんなもんなんだろうという興味本位の実験でもあります。

---

## 🎯 目指したこと

市販のAIレコーダー（例：Plaud Note Pro）はたしかに優秀です。  
ただし「**月額課金＋クラウド依存**」という部分に少し抵抗がありました。  

- 自分の声や会話をクラウドに上げたくない  
- 毎月お金を払い続けるのは現実的でない  
- どうせなら、自分のMac上で完結させたい  

そう思い、**「自分専用のAIレコーダー」をローカルで構築する**という挑戦を始めました。

---

## 🧩 目標
目指したのは以下のような流れです。

[録音デバイス] → (音声ファイル転送) → [Mac]
↓
[WhisperX]：文字起こし（＋タイムスタンプ同期）
↓
[Pyannote.audio]：話者分離（誰が話したか識別）
↓
[outputs/]：テキスト・字幕・構造化データ

## 🖥️ 使用環境

- macOS Sonoma  
- MacBook Air M3  
- Python 3.11（Homebrew経由でインストール）  
- GPUアクセラレーション：Metal（`CT2_USE_METAL=1`）

## ⚙️ 構築手順

### 1️⃣ Python仮想環境を作成
```bash
% /opt/homebrew/bin/python3.11 -m venv ~/venvs/whisperx
% source ~/venvs/whisperx/bin/activate
```
ターミナル上で`(whisperx)`と表示されればOK

### 2️⃣ WhisperX と Pyannote のインストール
```bash
% pip install git+https://github.com/m-bain/whisperX.git
% pip install "pyannote.audio>=3.1,<4.0"
```
WhisperXはOpenAI Whisperの拡張版で、時間情報付きの文字起こしを行えます。
長時間の録音を想定していたので、時間情報がついてたら便利かなぁくらいの温度感で選定しました。

Pyannote.audioは音声から話者を識別するためのOSSライブラリです。
まあ複数人で話すこともあるし、誰が話しているかわかったほうが便利かなぁくらいの温度感で選定しました。

### 3️⃣ Hugging Face トークンの発行
Hugging Face（ハギングフェイス）は、
世界中のAI開発者が機械学習モデルを公開・共有できるプラットフォームです。

Pyannoteを利用するために登録と利用規約に「同意（Agree）」する必要がありました。

その後、下記リンクからトークンを発行：
👉 https://huggingface.co/settings/tokens

ターミナルで以下を実行します。
```bash
% export HF_TOKEN="hf_xxxxxxxxxxxxx"
% echo 'export HF_TOKEN="hf_xxxxxxxxxxxxx"' >> ~/.zprofile
```
これで再起動後もトークンが自動で読み込まれるようになります。


## ディレクトリ構成
```bash
whisperx_test/
 ├── audio/      ← 録音ファイル(m4a/mp3)
 ├── outputs/    ← 結果ファイル（txt, srt, jsonなど）
```

録音した音声は audio/ に置き、出力は outputs/ に生成されます。

## 🚀 実行コマンド
以下が実際に使用したコマンドです。
initial_promptkで会話の文脈を補足すると精度が上がるとのこと。
```bash
% export CT2_USE_METAL=1
% whisperx ~/whisperx_test/audio/sample.m4a \
  --model large-v3 \
  --language ja \
  --initial_prompt "妻との会話です。子どもの名前はxxx、私はxxx、妻はxxxです。朝の準備やお出かけの話をしています。" \
  --output_dir ~/whisperx_test/outputs \
  --compute_type int8 \
  --diarize --vad_method pyannote \
  --hf_token "$HF_TOKEN"
```

## 結果
2分程度の妻との会話を書き起こしてみました

```bash
[SPEAKER_02]: 明日の準備はこれで終わり。これ、今何の準備?明日、朝時間内からxxx`子供の名前`の洗濯をする準備。じゃあ、明日とりあえず何個サロンつくやん。その後に、
[SPEAKER_02]: 化粧をして、行きながら行く途中でドライブスルーとかコンビニに行って、ご飯を買って、大人はそれを食べながら行って、美味しい後援についてはxxx`子供の名前`のご飯。ついてかな?出る前。出てる最中でもいいかなって思ってた。出てるんすか?ああ、それでもいいな。xxx`子供の名前`が寝てた?運転しながら、xxx`私の名前`運転してる後ろで壊せるの。
[SPEAKER_02]: まあ、やってみて。一旦。最悪の場合は、時間がないとなったらそうする。化粧している間は、ベビーカーを乗せておくって感じだよ。その時に、飯を食わせれそうだったら、そこで食わせるとかもありやけどな。時間によるな。それに合わせて朝ごはん食べさすからさ、もうほんじゃ朝ごはん早めにした方がいい。
[SPEAKER_04]: 4、5時間開けば、昼ごはんちゃんと食べてくれると思う。どっちがいいだろう?メイクが10時から何時?メイクは、11時半だったかな。
[SPEAKER_04]: メイク中のご飯は早すぎる?早くつく可能性もあるけど、メイク1時間半あるとは限らないし。
[SPEAKER_02]: もう少しポーズを見ておかないと、1時間くらいしか写真撮影の時間がないから、もう少し見ておこう。
```

うーん、話者分離はほとんどできてないです
ちょっと会話内容が短すぎたのかな
関西弁かつ早口で話しすぎたのもありそう

文字起こしはだいたいできてて問題なさそうです！
ここに別途AIかまして整形するなどすれば困らなさそう

## 次回
話者分離が微妙だったので、もう少し調整してみたりいろいろと調べてみます
また使う場面などを考えて話者分離等が本当に必要なのかもも再度考慮すべきかも

とはいえ、録音した何気ない会話が「文字」として手元に残る体験について、ノートPCのローカル環境で構築できるなんて小さな未来を感じました
未知の技術にふれる機会をどんどん増やしていきたい